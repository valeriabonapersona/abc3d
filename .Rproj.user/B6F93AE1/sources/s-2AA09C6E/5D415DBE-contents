'
  Cleaning functions

  Authors: Valeria Bonapersona & Heike Schuler
'


# Specify damaged areas ---------------------------------------------------
#' @title Specify damaged areas per sample
#' @description specify_damage() uses tidyr functions to filter
#' a dataframe containing a summary of damaged areas for all samples
#' and adapt it for later use in cleaning functions.
#'
#'
#' @param sample_id String used to select relevant sample.
#' @param data Dataframe with summary of damaged brain areas for all samples.
#' Long format in which each row is a damaged area. Requires the following
#' variables: "sample" with the name of the sample;
#' "area" with the acronym of damaged brain area according to Allen Brain Atlas
#' nomenclature; "hemisphere" to specify which hemisphere.
#'
#' @export
#' @return
#'
#' @examples
#' x <- data.frame(
#' sample = c(1,1,2,3),
#' area = c("BLA", "VTA", "CA1", "DG"),
#' hemisphere = c("left", "left", "right", "right")
#' )
#'
#' my_sample <- 1
#'
#' specify_damage(my_sample, x)

## add checks for data to be a dataframe
## add warning is sample_id not in data$sample.
specify_damage <- function(sample_id, data) {

  # check atlas is a dataframe
  assertthat::assert_that(is.data.frame(data))

  # check parent_acronym and acronym are the var names of the df
  assertthat::has_name(data, "sample")
  assertthat::has_name(data, "area")
  assertthat::has_name(data, "hemisphere")

  # check only one sample provided has length 1
  assertthat::are_equal(length(sample), 1)

  data %>%
    dplyr::filter(sample == sample_id) %>%
    dplyr::mutate(area_hemisphere = paste(area, hemisphere, sep = "_")) %>%
    droplevels()

}


# Clean_counts ------------------------------------------------------------
## ADD MASKS AS DATA OF PACKAGE
#' @title Clean xyz coordinates of identified cells
#' @description This function performs the following actions: 1) removes the
#' halo around the brain and ventricles, 2) filters brain areas of interest,
#' 3) removes damaged areas, and 4) reimputes the damaged areas by mirroring the
#' other hemisphere. clean_counts() saves two .RDS files in the path specified
#' for each sample processed. The first file (*clean_counts.RDS) contains the xyz
#' coordinates of cells that met the cleaning criteria, as well as their categorization
#' to brain areas of interest by the user. The second file
#' (*_removed_counts_summary.RDS) contains information about the removed counts during the procedure.
#'
#'
#' @param sample_id String used to save output. Please do not use spaces.
#' @param data Dataframe with cell coordinates for one sample.
#' Requires variables "xPos", "yPos" and "zPos" for x, y, z coordinates respectively; "id"
#' for code of the brain areas according to the Allen Brain Atlas.
#' @param atlas Dataframe with meta-data of Allen Brain Atlas areas. It can be generated by running the
#' preparation script "atlas_tree.R". Requires variables: "id" for numerical value of ABA areas;
#' "name" for character value; "acronym" for nomenclature; "parent_acronym" for the parent ABA it belongs to;
#' "category" for categorization of brain areas difficult to interpret, see XX for details; "my_grouping"
#' for your categorization of brain areas.
#' @param damaged_areas Dataframe with list of damaged brain areas of all samples. By using
#' the function specify_damage(), relevant damaged areas will be automatically selected.
#' Requires the following variables "area" with the acronym of the brain area that matches
#' the "grouping" variable of the areas dataframe (see above); "hemisphere" which specify
#' the hemisphere where the damage occurs ("right", "left").
#' @param out_mask Mask to identify outer part of brain to be removed due to halo.
#' Ask Heike more info: Created in python by finding all 0 that border the brain (next to non-zero values)
#' from there move 3 voxels in all directions (k). Create new matrix with non-zero values for
#' 3 voxels around k.
#' @param vent_mask Mask to identify outer part of the ventricles to be removed due
#' to halo and unspecific binding of the antibody. Ask Heike more info
#' @param warning_percentage Number between 0 and 1. It defines a threshold after which a warning message is
#' delivered. The warning message specifies if brain areas removed during the cleaning procedure had
#' (abnormally) high cells. 0 will never return a warning, 1 will always.
#' @param my_path String to specify path where outputs will be saved.
#'
#' @return
#' @export
#'
#' @examples For a thorough example, please see XX.

clean_counts <- function(sample_id, data, atlas, damaged_areas,
                         out_mask = out_mask, vent_mask = vent_mask,
                         warning_percentage = 0.2, my_path) {


  ## add checks for my_path and sample_id (must be strings)
  ## add checks for each dataframe added to check whether they are in the write format
  ## and their variables are in the write format
  ## specify somewhere the reason for which we split as we split it


  ## checks
  # atlas must have xyz coordinates and id
  # check atlas and data are a dataframe
  assertthat::assert_that(is.data.frame(atlas))
  assertthat::assert_that(is.data.frame(data))

  # check all required variables are present
  ## data
  assertthat::has_name(data, "xPos")
  assertthat::has_name(data, "yPos")
  assertthat::has_name(data, "zPos")
  assertthat::has_name(data, "id")

  ## atlas
  assertthat::has_name(atlas, "id")
  assertthat::has_name(atlas, "name")
  assertthat::has_name(atlas, "acronym")
  assertthat::has_name(atlas, "parent_acronym")
  assertthat::has_name(atlas, "category")
  assertthat::has_name(atlas, "my_grouping")

  # warning_percentage must be between 0 and 1
  assertthat::is.number(warning_percentage)
  if(!warning_percentage >= 0 & ! warning_percentage <= 1) stop ("warning_percentage provided is not a number between 0 and 1")



  # Match  info categorization brain area  ----------------------------------
  data <- data.frame(data,
                     atlas[match(data$id, atlas$id),
                           c("category", "my_grouping")])
  # recode warning_percentage
  warn <- 1 - warning_percentage


  # Specify damaged areas ---------------------------------------------------
  damaged_areas_sample <- specify_damage(sample_id = sample, data = damaged_areas)

  # Areas checks ------------------------------------------------------------
  ## correct if you change category variable levels
  if ( any(data$category %in% c(1,3)) ) warning("Subcategorized areas return non-zero counts, in disagreement with Allen Bran Atlas.
    Removed, but categorization must be checked.")

  if (data %>% filter(category == 4) %>% count() > nrow(data)*warn) warning("Trimmed areas have disproportionately high counts.")
  if (data %>% filter(category == 5) %>% count() > nrow(data)*warn) warning("Sub-categorized, not interpretable areas have disproportionately high counts.")
  if (data %>% filter(category == 7) %>% count() > nrow(data)*warn) warning("Not reliable areas have disproportionately high counts.")

  # Cleaning -------------------------------------------------------------

  clean_data <-
    data %>%

    # Remove halo
    mutate_at(vars(xPos, yPos, zPos), floor) %>%
    anti_join(rbind(out_mask, vent_mask)) %>%
    { . ->> no_halo} %>% # saves intermediate output

    # Remove background and brain areas not interpretables
    filter(id != 0,
           category %in% c(0,2))  %>%
    { . ->> no_background} %>% # saves intermediate output ##CHECK ALL AREAS HAVE CATEGORIZATION

    # Split zPos (hemispheres) into half. Left areas will be < 0, right areas will be > 0.
    mutate(zPos = zPos - 228, #dimensions of template: x*y*456
           hemisphere = case_when(zPos < 0 ~ "left",
                                  zPos > 0 ~ "right",
                                  TRUE ~ "midline")) %>%

    { . ->> hemisphere_sep} %>% # saves intermediate output

    # Clean up factors
    droplevels() %>% # necessary?

    # Remove damaged areas
    mutate(grouping_hemisphere = paste(.$my_grouping, hemisphere, sep="_"),
           potentially_damaged = case_when(grouping_hemisphere %in%
                                             damaged_areas_sample$area_hemisphere ~ "yes",
                                           TRUE ~ "no")) %>%

    { . ->> pot_damaged}  %>% # saves intermediate output

    filter(potentially_damaged != "yes") %>%

    # Impute mirror of other hemisphere for damaged brain areas removed
    full_join(
      pot_damaged %>%
        filter(my_grouping %in% damaged_areas_sample$area,
               !hemisphere %in% c(levels(damaged_areas_sample$hemisphere), "midline")) %>%
        mutate(zPos = .$zPos * -1,
               hemisphere = case_when(.$hemisphere == "right" ~ "left",
                                      .$hemisphere == "left" ~ "right"),
               grouping_hemisphere = paste(.$my_grouping, hemisphere, sep = "_"))
    )




  # Save output cleancounts in temp file
  saveRDS(clean_data, file = paste0(my_path, sample_id, "_clean_cells.RDS"))

  # Removed counts -------------------------------------------------------------

  removed_counts <- data.frame(
    "sample_id" = sample_id,
    "initial_counts" = nrow(data),
    "halo_removal" = (nrow(data) - nrow(no_halo)),
    "background_removal" = (nrow(no_halo) - nrow(no_background)),
    "damaged_counts_removed" = nrow(pot_damaged[pot_damaged$potentially_damaged == "yes",]),
    "replacement_counts" = nrow(pot_damaged[pot_damaged$my_grouping %in% damaged_areas_sample$area &
                                              !pot_damaged$hemisphere %in% c(levels(damaged_areas_sample$hemisphere), "midline"),]),
    "final_counts" = nrow(clean_data))

  saveRDS(removed_counts, file = paste0(my_path, sample_id, "_removed_counts_summary.RDS"))


  # Warnings ----------------------------------------------------------------
  ## midline values --> add this in the document where you calculate per brain area
  if ("midline" %in% levels(factor(clean_data$hemisphere)) == TRUE) warning(
    'Some counts are on the midline and cannot be divided in right / left hemisphere.
  For details see *sample*_removed_counts_summary.RDS in specified folder.')

  if ("yes" %in% pot_damaged$potentially_damaged == TRUE) warning(
    "Counts from damaged areas have been deleted and replaced by mirroring cells of that brain area of the opposite hemisphere.
  For details see *sample*_removed_counts_summary.RDS in specified folder.")



  # Return ------------------------------------------------------------------
  print(paste0("Cleaned data of sample '", sample_id,
               "' has been saved in the specified folder."))
}


####### this part can be later deleted
## check no weird areas >> categories 1 and 3 should not be present
# categories:
#   0 = included
#   1 = subcategorized (returns null counts)
#   2 = subcategorized, non no-zero, interpretable
#   3 = subcategorization does not exist in ABA, returns null
#   4 = trimmed areas (trimmed by who??)
#   5 = subcategorized, non no-zero, not interpretable
#   6 = fiber tract
#   7 = not reliable, around ventricles and small





# Normalization with boxcox -----------------------------------------------
#' @title Normalize cell counts with boxcox transformation
#' @description Wrapper functon to boxcox from EnvStats to be able to normalize
#' in one step within pipes %>% structure
#'
#'
#' @param x Numeric vector with values to normalize
#'
#' @return
#' @export
#'
#' @examples
#' x <- rpois(100, 6)
#' y <- normalize(x)
#'
#' par(mfrow=c(1,2))
#' hist(x)
#' hist(y)
#' par(mfrow=c(1,1))

normalize <- function(x) {

  my_lambda <- EnvStats::boxcox(x, optimize = TRUE)

  # transform based on lambda
  EnvStats::boxcoxTransform(x, my_lambda[['lambda']])
}
